{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, GPT2Tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "vocab_size = 10\n",
    "config = AutoConfig.from_pretrained(\"gpt2\", vocab_size=vocab_size, n_ctx=11, n_head=3, n_layer=1)\n",
    "model = AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 7.9M parameters\n"
     ]
    }
   ],
   "source": [
    "def model_size(model):\n",
    "    return sum(t.numel() for t in model.parameters())\n",
    "\n",
    "print(f'Model size: {model_size(model)/1000**2:.1f}M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'sortingLLM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  14%|█▎        | 4.29M/31.5M [00:04<00:24, 1.13MB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[263], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49msave_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mmodels/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m model_ckpt, push_to_hub\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:1866\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, **kwargs)\u001b[0m\n\u001b[1;32m   1859\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1860\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe model is bigger than the maximum size per checkpoint (\u001b[39m\u001b[39m{\u001b[39;00mmax_shard_size\u001b[39m}\u001b[39;00m\u001b[39m) and is going to be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1861\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msplit in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(shards)\u001b[39m}\u001b[39;00m\u001b[39m checkpoint shards. You can find where each parameters has been saved in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1862\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex located at \u001b[39m\u001b[39m{\u001b[39;00msave_index_file\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1863\u001b[0m     )\n\u001b[1;32m   1865\u001b[0m \u001b[39mif\u001b[39;00m push_to_hub:\n\u001b[0;32m-> 1866\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upload_modified_files(\n\u001b[1;32m   1867\u001b[0m         save_directory,\n\u001b[1;32m   1868\u001b[0m         repo_id,\n\u001b[1;32m   1869\u001b[0m         files_timestamps,\n\u001b[1;32m   1870\u001b[0m         commit_message\u001b[39m=\u001b[39;49mcommit_message,\n\u001b[1;32m   1871\u001b[0m         token\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39muse_auth_token\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1872\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/transformers/utils/hub.py:729\u001b[0m, in \u001b[0;36mPushToHubMixin._upload_modified_files\u001b[0;34m(self, working_dir, repo_id, files_timestamps, commit_message, token, create_pr)\u001b[0m\n\u001b[1;32m    724\u001b[0m         operations\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    725\u001b[0m             CommitOperationAdd(path_or_fileobj\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(working_dir, file), path_in_repo\u001b[39m=\u001b[39mfile)\n\u001b[1;32m    726\u001b[0m         )\n\u001b[1;32m    728\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUploading the following files to \u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(modified_files)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m create_commit(\n\u001b[1;32m    730\u001b[0m     repo_id\u001b[39m=\u001b[39;49mrepo_id, operations\u001b[39m=\u001b[39;49moperations, commit_message\u001b[39m=\u001b[39;49mcommit_message, token\u001b[39m=\u001b[39;49mtoken, create_pr\u001b[39m=\u001b[39;49mcreate_pr\n\u001b[1;32m    731\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:828\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_as_future(fn, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    827\u001b[0m \u001b[39m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m--> 828\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2695\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[0;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit, run_as_future)\u001b[0m\n\u001b[1;32m   2686\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   2687\u001b[0m files_to_copy \u001b[39m=\u001b[39m fetch_lfs_files_to_copy(\n\u001b[1;32m   2688\u001b[0m     copies\u001b[39m=\u001b[39mcopies,\n\u001b[1;32m   2689\u001b[0m     repo_type\u001b[39m=\u001b[39mrepo_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2693\u001b[0m     endpoint\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint,\n\u001b[1;32m   2694\u001b[0m )\n\u001b[0;32m-> 2695\u001b[0m upload_lfs_files(\n\u001b[1;32m   2696\u001b[0m     additions\u001b[39m=\u001b[39;49m[addition \u001b[39mfor\u001b[39;49;00m addition \u001b[39min\u001b[39;49;00m additions \u001b[39mif\u001b[39;49;00m upload_modes[addition\u001b[39m.\u001b[39;49mpath_in_repo] \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mlfs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2697\u001b[0m     repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m   2698\u001b[0m     repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[1;32m   2699\u001b[0m     token\u001b[39m=\u001b[39;49mtoken \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken,\n\u001b[1;32m   2700\u001b[0m     endpoint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint,\n\u001b[1;32m   2701\u001b[0m     num_threads\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[1;32m   2702\u001b[0m )\n\u001b[1;32m   2703\u001b[0m commit_payload \u001b[39m=\u001b[39m prepare_commit_payload(\n\u001b[1;32m   2704\u001b[0m     operations\u001b[39m=\u001b[39moperations,\n\u001b[1;32m   2705\u001b[0m     upload_modes\u001b[39m=\u001b[39mupload_modes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2709\u001b[0m     parent_commit\u001b[39m=\u001b[39mparent_commit,\n\u001b[1;32m   2710\u001b[0m )\n\u001b[1;32m   2711\u001b[0m commit_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/api/\u001b[39m\u001b[39m{\u001b[39;00mrepo_type\u001b[39m}\u001b[39;00m\u001b[39ms/\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m/commit/\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:393\u001b[0m, in \u001b[0;36mupload_lfs_files\u001b[0;34m(additions, repo_type, repo_id, token, endpoint, num_threads)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(filtered_actions) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    392\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mUploading 1 LFS file to the Hub\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m     _wrapped_lfs_upload(filtered_actions[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    396\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUploading \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(filtered_actions)\u001b[39m}\u001b[39;00m\u001b[39m LFS files to the Hub using up to \u001b[39m\u001b[39m{\u001b[39;00mnum_threads\u001b[39m}\u001b[39;00m\u001b[39m threads concurrently\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    397\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:383\u001b[0m, in \u001b[0;36mupload_lfs_files.<locals>._wrapped_lfs_upload\u001b[0;34m(batch_action)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     operation \u001b[39m=\u001b[39m oid2addop[batch_action[\u001b[39m\"\u001b[39m\u001b[39moid\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m--> 383\u001b[0m     lfs_upload(operation\u001b[39m=\u001b[39;49moperation, lfs_batch_action\u001b[39m=\u001b[39;49mbatch_action, token\u001b[39m=\u001b[39;49mtoken)\n\u001b[1;32m    384\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    385\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError while uploading \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moperation\u001b[39m.\u001b[39mpath_in_repo\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to the Hub.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/lfs.py:223\u001b[0m, in \u001b[0;36mlfs_upload\u001b[0;34m(operation, lfs_batch_action, token)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    220\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    221\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMalformed response from LFS batch endpoint: `chunk_size` should be an integer. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mchunk_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         )\n\u001b[0;32m--> 223\u001b[0m     _upload_multi_part(operation\u001b[39m=\u001b[39;49moperation, header\u001b[39m=\u001b[39;49mheader, chunk_size\u001b[39m=\u001b[39;49mchunk_size, upload_url\u001b[39m=\u001b[39;49mupload_action[\u001b[39m\"\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     _upload_single_part(operation\u001b[39m=\u001b[39moperation, upload_url\u001b[39m=\u001b[39mupload_action[\u001b[39m\"\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/lfs.py:319\u001b[0m, in \u001b[0;36m_upload_multi_part\u001b[0;34m(operation, header, chunk_size, upload_url)\u001b[0m\n\u001b[1;32m    310\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    311\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhf_transfer is enabled but does not support uploading from bytes or BinaryIO, falling back to regular\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m upload\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m     use_hf_transfer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    316\u001b[0m response_headers \u001b[39m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m     _upload_parts_hf_transfer(operation\u001b[39m=\u001b[39moperation, sorted_parts_urls\u001b[39m=\u001b[39msorted_parts_urls, chunk_size\u001b[39m=\u001b[39mchunk_size)\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m use_hf_transfer\n\u001b[0;32m--> 319\u001b[0m     \u001b[39melse\u001b[39;00m _upload_parts_iteratively(operation\u001b[39m=\u001b[39;49moperation, sorted_parts_urls\u001b[39m=\u001b[39;49msorted_parts_urls, chunk_size\u001b[39m=\u001b[39;49mchunk_size)\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m \u001b[39m# 3. Send completion request\u001b[39;00m\n\u001b[1;32m    323\u001b[0m completion_res \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mpost(\n\u001b[1;32m    324\u001b[0m     upload_url,\n\u001b[1;32m    325\u001b[0m     json\u001b[39m=\u001b[39m_get_completion_payload(response_headers, operation\u001b[39m.\u001b[39mupload_info\u001b[39m.\u001b[39msha256\u001b[39m.\u001b[39mhex()),\n\u001b[1;32m    326\u001b[0m     headers\u001b[39m=\u001b[39mLFS_HEADERS,\n\u001b[1;32m    327\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/lfs.py:375\u001b[0m, in \u001b[0;36m_upload_parts_iteratively\u001b[0;34m(operation, sorted_parts_urls, chunk_size)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mfor\u001b[39;00m part_idx, part_upload_url \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sorted_parts_urls):\n\u001b[1;32m    370\u001b[0m     \u001b[39mwith\u001b[39;00m SliceFileObj(\n\u001b[1;32m    371\u001b[0m         fileobj,\n\u001b[1;32m    372\u001b[0m         seek_from\u001b[39m=\u001b[39mchunk_size \u001b[39m*\u001b[39m part_idx,\n\u001b[1;32m    373\u001b[0m         read_limit\u001b[39m=\u001b[39mchunk_size,\n\u001b[1;32m    374\u001b[0m     ) \u001b[39mas\u001b[39;00m fileobj_slice:\n\u001b[0;32m--> 375\u001b[0m         part_upload_res \u001b[39m=\u001b[39m http_backoff(\u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m, part_upload_url, data\u001b[39m=\u001b[39;49mfileobj_slice)\n\u001b[1;32m    376\u001b[0m         hf_raise_for_status(part_upload_res)\n\u001b[1;32m    377\u001b[0m         headers\u001b[39m.\u001b[39mappend(part_upload_res\u001b[39m.\u001b[39mheaders)\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:258\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     conn\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    497\u001b[0m         method,\n\u001b[1;32m    498\u001b[0m         url,\n\u001b[1;32m    499\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    500\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    501\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    502\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    503\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    504\u001b[0m         enforce_content_length\u001b[39m=\u001b[39;49menforce_content_length,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/projects/simpleLLM/venv/lib/python3.10/site-packages/urllib3/connection.py:409\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%x\u001b[39;00m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(chunk), chunk))\n\u001b[1;32m    408\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(chunk)\n\u001b[1;32m    411\u001b[0m \u001b[39m# Regardless of whether we have a body or not, if we're in\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39m# chunked mode we want to send an explicit empty chunk.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39mif\u001b[39;00m chunked:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:999\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    997\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mhttp.client.send\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, data)\n\u001b[1;32m    998\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 999\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock\u001b[39m.\u001b[39;49msendall(data)\n\u001b[1;32m   1000\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1001\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mIterable):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1237\u001b[0m, in \u001b[0;36mSSLSocket.sendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         amount \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(byte_view)\n\u001b[1;32m   1236\u001b[0m         \u001b[39mwhile\u001b[39;00m count \u001b[39m<\u001b[39m amount:\n\u001b[0;32m-> 1237\u001b[0m             v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(byte_view[count:])\n\u001b[1;32m   1238\u001b[0m             count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m v\n\u001b[1;32m   1239\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1206\u001b[0m, in \u001b[0;36mSSLSocket.send\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1203\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1204\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1205\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mwrite(data)\n\u001b[1;32m   1207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msend(data, flags)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  14%|█▍        | 4.37M/31.5M [00:20<00:24, 1.13MB/s]"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"models/\" + model_ckpt, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberTokenizer:\n",
    "  def __init__(self, numbers_qty=10):\n",
    "    self.numbers_qty = numbers_qty\n",
    "    self.pad_token = '-1'\n",
    "    self.encoder = {str(v):i for i,v in enumerate(range(-1, numbers_qty-2))}\n",
    "    self.decoder = {i:str(v) for i,v in enumerate(range(-1, numbers_qty-2))}\n",
    "    self.pad_token_id = self.encoder[self.pad_token]\n",
    "\n",
    "  def decode(self, token_ids):\n",
    "    return ' '.join(self.decoder[t] for t in token_ids)\n",
    "\n",
    "  def __call__(self, text):\n",
    "    return [self.encoder[t] for t in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = NumberTokenizer(vocab_size)\n",
    "tokenizer(\"0 1 2 3 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SortDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Sort problem. E.g. for problem length 6:\n",
    "    Input:  0 0 2 1 0 1 -> Output:  0 0 0 1 1 2\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:   0 0 2 1 0 1 0 0 0 1 1\n",
    "    output:  I I I I I 0 0 0 1 1 2\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=6, num_digits=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "        self.num_digits = num_digits\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 10000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return self.num_digits\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return self.length * 2 - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # use rejection sampling to generate an input example from the desired split\n",
    "        while True:\n",
    "            # generate some random integers\n",
    "            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n",
    "            # half of the time let's try to boost the number of examples that \n",
    "            # have a large number of repeats, as this is what the model seems to struggle\n",
    "            # with later in training, and they are kind of rate\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                if inp.unique().nelement() > self.length // 2:\n",
    "                    # too many unqiue digits, re-sample\n",
    "                    continue\n",
    "            # figure out if this generated example is train or test based on its hash\n",
    "            h = hash(pickle.dumps(inp.tolist()))\n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        # solve the task: i.e. sort\n",
    "        sol = torch.sort(inp)[0]\n",
    "\n",
    "        # concatenate the problem specification and the solution\n",
    "        cat = torch.cat((inp, sol), dim=0)\n",
    "\n",
    "        # the inputs to the transformer will be the offset sequence\n",
    "        x = cat[:-1].clone()\n",
    "        y = cat[1:].clone()\n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        y[:self.length-1] = int(tokenizer.pad_token)\n",
    "        x, y = ' '.join(map(str, x.tolist())), ' '.join(map(str, y.tolist()))\n",
    "        tokenized_input = tokenizer(x)\n",
    "        tokenized_output = tokenizer(y)\n",
    "        return torch.tensor(tokenized_input), torch.tensor(tokenized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SortDataset('train')\n",
    "test_dataset = SortDataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 2, 1, 2, 3, 3, 1, 1, 2, 2, 3]), tensor([0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# from datasets import load_dataset\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "batch_size = 50\n",
    "input_size = 11\n",
    "input_to_sort_size = 6\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "dataset = train_dataset\n",
    "data = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Dont take in account the list of input to sort\n",
    "attention_mask = torch.ones((batch_size, input_size), dtype=torch.long)\n",
    "attention_mask[:, :input_to_sort_size-1] = 0\n",
    "\n",
    "model, optimizer, data = accelerator.prepare(model, optimizer, data)\n",
    "attention_mask = attention_mask.to(accelerator.device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "  for source, targets in data:\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.nn.functional.cross_entropy(model(source).logits.flatten(end_dim=1), targets.flatten(end_dim=1), ignore_index=tokenizer.pad_token_id)\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(input, solution_length=6):\n",
    "  model.eval()\n",
    "  input = torch.tensor(tokenizer(input))\n",
    "  input = input.to(accelerator.device)\n",
    "  solution = []\n",
    "  for i in range(solution_length):\n",
    "    output = model(input)\n",
    "    predicted = output.logits[-1].argmax()\n",
    "    input = torch.cat((input, predicted.unsqueeze(0)), dim=0)\n",
    "    solution.append(predicted.cpu().item())\n",
    "  return tokenizer.decode(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0 0 1 1 2'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = '0 2 1 1 0'\n",
    "generate_solution(test_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
